{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "#filename    = '/home/axel/PycharmProjects/pax/tpc_kr_150410_8k.hdf5'\n",
    "filename     = '/home/axel/ownCloud/documents/Masterarbeit/TPC/rawdata/2015_11_02/Kr83m_valve_50min_open/Kr83m_gas_cold_151102_1k.root'\n",
    "#filename    = '/home/axel/ownCloud/documents/Masterarbeit/TPC/rawdata/2015_10_02/Kr_Measurement_1000TH_1_151002.hdf5'\n",
    "#filename    = '/media/axel/cf2b7088-fe0f-419a-a101-07493d88971c/kabelchange.hdf5.hdf5'\n",
    "file_format = 'root'\n",
    "#loglevel    = 'DEBUG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "log = logging.getLogger('Gaseous basic statistics')\n",
    "log.setLevel('DEBUG')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib   # Needed for font size spec, color map transformation function bla bla\n",
    "%matplotlib inline\n",
    "matplotlib.rc('font', size=16)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.dates as md\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "# Optional progress bar\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    log.debug(\"You don't have tqdm, I can't give you a nice progress bar...\")\n",
    "    def dummy(*args,**kwargs):\n",
    "        return args[0]\n",
    "    tqdm = dummy\n",
    "\n",
    "from recarray_tools import append_fields, fields_view, group_by, filter_on_fields, fields_data\n",
    "\n",
    "peak_types = [b's1', b's2', b'unknown', b'noise', b'lone_hit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Gaseous basic statistics:Now loading /home/axel/ownCloud/documents/Masterarbeit/TPC/rawdata/2015_11_02/Kr83m_valve_50min_open/Kr83m_gas_cold_151102_1k.root (file format=root)...\n",
      "WARNING:TableWriter:ROOT read support is experimental!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Strange branch events in tree tree?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a3dd52e1cf2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mioformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflat_data_formats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mioformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mevents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mioformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tree'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mpeaks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mioformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Peak'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/axel/PycharmProjects/pax/pax/formats.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(self, df_name)\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_type\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Strange branch %s in tree %s?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetTitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'S'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Strange branch events in tree tree?"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Load the data\n",
    "##\n",
    "try:\n",
    "    events = None\n",
    "    hits = None\n",
    "    peaks = None\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "log.debug(\"Now loading %s (file format=%s)...\" % (filename, file_format))\n",
    "\n",
    "# Slurp peaks and events into memory\n",
    "# WARNING: For a large dataset, use pax to remove big low-level fields first\n",
    "# (area_per_channel, does_channel_contribute, does_channel_have_noise)\n",
    "try:\n",
    "    # Load the file using pax 3's IO code\n",
    "    from pax.formats import flat_data_formats\n",
    "    ioformat = flat_data_formats[file_format]()\n",
    "    ioformat.open(filename, 'r')\n",
    "    events = ioformat.read_data('tree')\n",
    "    try:\n",
    "        peaks = ioformat.read_data('Peak')\n",
    "    except KeyError:\n",
    "        peaks = None\n",
    "        log.info(\"There is no peak table\")\n",
    "    hits = ioformat.read_data('hits')\n",
    "    ioformat.close()\n",
    "except ImportError:\n",
    "    log.debug(\"You don't have pax 3 installed, falling back to HDF5-specific code...\")\n",
    "    import h5py\n",
    "    f = h5py.File(filename)\n",
    "    events = f.get('Event')[:]\n",
    "    peaks = f.get('Peak')[:]\n",
    "    hits = f.get('hits')[:]\n",
    "    f.close()\n",
    "#if peaks != None:\n",
    "    log.info(\"Loaded %s, found %d hits (%0.2f MB RAM), clustered into %d peaks (%0.2f MB RAM) in %d events (%0.2f MB RAM)\" % (\n",
    "    filename, len(hits), hits.nbytes/10**6, len(peaks), peaks.nbytes/10**6, len(events), events.nbytes/10**6))\n",
    "#if len(events) == 0:\n",
    "#    raise ValueError(\"You don't have any events in this dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log.info(\"Loaded %s, found %d hits (%0.2f MB RAM), clustered into %d peaks (%0.2f MB RAM) in %d events (%0.2f MB RAM)\" % (\n",
    "    filename, len(hits), hits.nbytes/10**6, len(peaks), peaks.nbytes/10**6, len(events), events.nbytes/10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding extra fields\n",
    "log.info(\"Loaded %d events (%0.2f MB RAM)\" %(len(events), events.nbytes/1e6))\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.set_ylabel(\"rate [events / s]\")\n",
    "ax.set_xlabel(\"time [s]\")\n",
    "ax.set_title(\"event rate after opening valve to Kr83m source\")\n",
    "a = ax.hist((events[\"start_time\"]-events[\"start_time\"][0])//1e9, bins=(events[\"start_time\"][-1]-events[\"start_time\"][0])//1e9 , histtype=\"step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log.info(\"Found %d hits (%s MB RAM)\"% (len(hits),hits.nbytes//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(16,20), squeeze=False)\n",
    "area_right_boundary = 200\n",
    "area_bins = 100\n",
    "\n",
    "if True:\n",
    "    \n",
    "    ### making histogram of hits\n",
    "    z = np.histogram(hits[\"channel\"], bins=14, range=(0,14))\n",
    "    print(z)\n",
    "    plt.cla()\n",
    "    ax1.bar(range(14),z[0], align=\"center\")\n",
    "    ax1.set_xlabel(\"channel number\")\n",
    "    ax1.set_ylabel(\"number of hits\")\n",
    "    ax1.set_title(\"total contribution of individual channels\")\n",
    "    ax1.set_xlim((-1,14))\n",
    "    \n",
    "    ### now checking how peaks were identified\n",
    "    peak_type_sums = dict()\n",
    "    for peaktype in peak_types:\n",
    "        z = (peaks[\"type\"] == peaktype)\n",
    "        peak_type_sums[peaktype] = sum(z)\n",
    "    ax2.bar(range(len(peak_types)), peak_type_sums.values(),align=\"center\")\n",
    "    ax2.set_ylabel(\"number of peaks\")\n",
    "    xlabels = [\"\"]\n",
    "    xlabels.extend(list(peak_type_sums.keys()))\n",
    "    ax2.set_xticklabels(labels= xlabels, rotation = 30)\n",
    "    ax2.set_title(\"classification of peaks\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    #ax2.set_xlim((-1,14))\n",
    "    \n",
    "    ### \n",
    "    import pandas as pd\n",
    "    # making a histogram of contributing channels towards peaks\n",
    "    # looking at coincidential peaks (type != lone_hit) \n",
    "    s1_peaks = peaks[\"type\"] == b\"s1\"\n",
    "    lone_hits = peaks[\"type\"] == b\"lone_hit\"\n",
    "\n",
    "    a = pd.DataFrame(peaks[s1_peaks][\"hits_per_channel\"])\n",
    "    b = pd.DataFrame(peaks[lone_hits][\"hits_per_channel\"])\n",
    "    ax3.bar(list(a), list(a.sum()),align=\"center\")\n",
    "    ax3.set_title(\"contribution to  's1' peaks\")\n",
    "    \n",
    "    ax4.set_title(\"contribution to 'lone hits' peaks\")\n",
    "    ax4.bar(list(b), list(b.sum()),align=\"center\")\n",
    "    \n",
    "    ax3.set_xlim((-1,14))\n",
    "    ax3.set_ylabel(\"number of hits\")\n",
    "    ax4.set_xlim((-1,14))\n",
    "    ax4.set_ylabel(\"number of hits\")\n",
    "    \n",
    "    ax5.set_title(\"peak area\")\n",
    "    ax5.hist(peaks[\"area\"], bins=area_bins, histtype=\"step\", range=(0,area_right_boundary), label=\"all peaks\")\n",
    "    ax5.hist(peaks[s1_peaks][\"area\"], bins=area_bins, histtype=\"step\", range=(0,area_right_boundary), label = \"s1\")\n",
    "    ax5.set_xlabel(\"peak area [p.e.]\")\n",
    "    #ax5.set_ylabel(\"#\")\n",
    "    ax5.set_xlim((0,area_right_boundary))\n",
    "    ax5.legend(loc=\"best\")\n",
    "    ax5.set_yscale(\"log\")\n",
    "    \n",
    "    ax6.set_title(\"number of peaks in events\")\n",
    "    ax6.hist(events[\"n_peaks\"], bins=10, histtype=\"step\", range=(0,10), align=\"left\")\n",
    "    ax6.set_xlabel(\"n_peaks\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Now finding events that contain >=2 peaks\n",
    "### Then plotting energy of first peak (ordered by area) vs the second peak\n",
    "\n",
    "multi_peak_events = events[events[\"n_peaks\"]>= 2]\n",
    "\n",
    "peak_by_event = group_by(peaks, \"Event\")\n",
    "\n",
    "main_peaks = []\n",
    "secondary_peaks = []\n",
    "\n",
    "for event_peaks in peak_by_event:\n",
    "    #print(event_peaks[\"area\"])\n",
    "    event_peaks = sorted(event_peaks, key= lambda x : x[\"area\"],reverse=True)\n",
    "    #print(event_peaks[0][\"area\"])\n",
    "    if len(event_peaks)<= 1:\n",
    "        continue\n",
    "    if event_peaks[0][\"n_contributing_channels\"] <= 1:\n",
    "        continue\n",
    "    if event_peaks[1][\"n_contributing_channels\"] <= 0:\n",
    "        continue\n",
    "    main_peaks.append(event_peaks[0])\n",
    "    secondary_peaks.append(event_peaks[1])\n",
    "    \n",
    "\n",
    "main_areas = [peak[\"area\"] for peak in main_peaks]\n",
    "secondary_areas =[peak[\"area\"] for peak in secondary_peaks]\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1, figsize=(16,10))\n",
    "plt.hist2d(main_areas, secondary_areas, bins=[120,120], range=((0,200),(0,20)))\n",
    "ax1.set_xlabel(\"area of main s1 peak [p.e.]\")\n",
    "ax1.set_ylabel(\"area of secondary s1 peak [p.e.]\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"counts\")\n",
    "#ax.set_xlim(0,150)\n",
    "#ax.set_ylim(0,50)\n",
    "\n",
    "#ax2.hist(peaks[\"index_of_maximum\"], bins=512, histtype=\"step\")\n",
    "#ax2.set_yscale(\"log\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "    \n",
    "#ax.hist2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted([1,2,3,4,8,5], reverse =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plot_by_channel\n",
    "print(hits.dtype)\n",
    "plot_by_channel.make_plot(hits, \"height\",range=(0,10), xlim=(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File(filename)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.hist(f.get(\"Peak\")[\"height\"], bins=100, histtype=\"step\", range=(0,500))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peaks.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
