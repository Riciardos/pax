{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "#filename    = '/home/axel/PycharmProjects/pax/tpc_kr_150410_8k.hdf5'\n",
    "filename     = '/home/axel/ownCloud/documents/Masterarbeit/TPC/rawdata/2015_10_02/Kr_Measurement_700TH_151002_with_peaks_light.hdf5.hdf5'\n",
    "#filename    = '/home/axel/ownCloud/documents/Masterarbeit/TPC/rawdata/2015_10_02/Kr_Measurement_1000TH_1_151002.hdf5'\n",
    "#filename    = '/home/axel/ownCloud/documents/Masterarbeit/TPC/rawdata/2015_10_05/testing_new_cable_on_ch9.hdf5'\n",
    "file_format = 'hdf5'\n",
    "#loglevel    = 'DEBUG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "log = logging.getLogger('Gaseous basic statistics')\n",
    "log.setLevel('DEBUG')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib   # Needed for font size spec, color map transformation function bla bla\n",
    "%matplotlib inline\n",
    "matplotlib.rc('font', size=16)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional progress bar\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    log.debug(\"You don't have tqdm, I can't give you a nice progress bar...\")\n",
    "    def dummy(*args,**kwargs):\n",
    "        return args[0]\n",
    "    tqdm = dummy\n",
    "\n",
    "from recarray_tools import append_fields, fields_view, group_by, filter_on_fields, fields_data\n",
    "\n",
    "peak_types = [b's1', b's2', b'unknown', b'noise', b'lone_hit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Gaseous basic statistics:Now loading /home/axel/ownCloud/documents/Masterarbeit/TPC/rawdata/2015_10_02/Kr_Measurement_700TH_151002_with_peaks_light.hdf5.hdf5 (file format=hdf5)...\n",
      "WARNING:TableWriter:pyROOT didn't import - if you use the ROOT format, pax will crash!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (Object 'hit' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a6c57b610fce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mpeaks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"There is no peak table\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mhits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mioformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Hit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mioformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/axel/PycharmProjects/pax/pax/formats.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(self, df_name, start, end)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_in_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/axel/PycharmProjects/pax/pax/formats.py\u001b[0m in \u001b[0;36mn_in_data\u001b[1;34m(self, df_name)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mn_in_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (-------src-dir-------/h5py/_objects.c:2458)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (-------src-dir-------/h5py/_objects.c:2415)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/axel/anaconda3/lib/python3.4/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0moid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0motype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (-------src-dir-------/h5py/_objects.c:2458)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (-------src-dir-------/h5py/_objects.c:2415)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open (-------src-dir-------/h5py/h5o.c:3507)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to open object (Object 'hit' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "##\n",
    "# Load the data\n",
    "##\n",
    "\n",
    "log.debug(\"Now loading %s (file format=%s)...\" % (filename, file_format))\n",
    "\n",
    "# Slurp peaks and events into memory\n",
    "# WARNING: For a large dataset, use pax to remove big low-level fields first\n",
    "# (area_per_channel, does_channel_contribute, does_channel_have_noise)\n",
    "try:\n",
    "    # Load the file using pax 3's IO code\n",
    "    from pax.formats import flat_data_formats\n",
    "    ioformat = flat_data_formats[file_format]()\n",
    "    ioformat.open(filename, 'r')\n",
    "    events = ioformat.read_data('Event')\n",
    "    try:\n",
    "        peaks = ioformat.read_data('Peak')\n",
    "    except KeyError:\n",
    "        peaks = None\n",
    "        log.info(\"There is no peak table\")\n",
    "    hits = ioformat.read_data('Hit')\n",
    "    ioformat.close()\n",
    "except ImportError:\n",
    "    log.debug(\"You don't have pax 3 installed, falling back to HDF5-specific code...\")\n",
    "    import h5py\n",
    "    f = h5py.File(filename)\n",
    "    events = f.get('Event')[:]\n",
    "    peaks = f.get('Peak')[:]\n",
    "    hits = f.get('Hit')[:]\n",
    "    f.close()\n",
    "if peaks != None:\n",
    "    log.info(\"Loaded %s, containing %d peaks (%0.2f MB RAM) and %d events (%0.2f MB RAM)\" % (\n",
    "    filename, len(peaks), peaks.nbytes/10**6, len(events), events.nbytes/10**6))\n",
    "if len(events) == 0:\n",
    "    raise ValueError(\"You don't have any events in this dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding extra fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(16,20), squeeze=False)\n",
    "area_right_boundary = 500\n",
    "area_bins = 100\n",
    "\n",
    "if True:\n",
    "    \n",
    "    ### making histogram of hits\n",
    "    z = plt.hist(hits[\"channel\"], bins=14)[0]\n",
    "    plt.cla()\n",
    "    ax1.bar(range(14),z, align=\"center\")\n",
    "    ax1.set_xlabel(\"channel number\")\n",
    "    ax1.set_ylabel(\"number of hits\")\n",
    "    ax1.set_title(\"total contribution of individual channels\")\n",
    "    ax1.set_xlim((-1,14))\n",
    "    \n",
    "    ### now checking how peaks were identified\n",
    "    peak_type_sums = dict()\n",
    "    for peaktype in peak_types:\n",
    "        z = (peaks[\"type\"] == peaktype)\n",
    "        peak_type_sums[peaktype] = sum(z)\n",
    "    ax2.bar(range(len(peak_types)), peak_type_sums.values(),align=\"center\")\n",
    "    ax2.set_ylabel(\"number of peaks\")\n",
    "    xlabels = [\"\"]\n",
    "    xlabels.extend(list(peak_type_sums.keys()))\n",
    "    ax2.set_xticklabels(labels= xlabels, rotation = 30)\n",
    "    ax2.set_title(\"classification of peaks\")\n",
    "    #ax2.set_xlim((-1,14))\n",
    "    \n",
    "    ### \n",
    "    import pandas as pd\n",
    "    # making a histogram of contributing channels towards peaks\n",
    "    # looking at coincidential peaks (type != lone_hit) \n",
    "    s1_peaks = peaks[\"type\"] == b\"s1\"\n",
    "    lone_hits = peaks[\"type\"] == b\"lone_hit\"\n",
    "\n",
    "    a = pd.DataFrame(peaks[s1_peaks][\"hits_per_channel\"])\n",
    "    b = pd.DataFrame(peaks[lone_hits][\"hits_per_channel\"])\n",
    "    ax3.bar(list(a), list(a.sum()),align=\"center\")\n",
    "    ax3.set_title(\"contribution to  's1' peaks\")\n",
    "    \n",
    "    ax4.set_title(\"contribution to 'lone hits' peaks\")\n",
    "    ax4.bar(list(b), list(b.sum()),align=\"center\")\n",
    "    \n",
    "    ax3.set_xlim((-1,14))\n",
    "    ax3.set_ylabel(\"number of hits\")\n",
    "    ax4.set_xlim((-1,14))\n",
    "    ax4.set_ylabel(\"number of hits\")\n",
    "    \n",
    "    ax5.set_title(\"peak area\")\n",
    "    ax5.hist(peaks[\"area\"], bins=area_bins, histtype=\"step\", range=(0,area_right_boundary), label=\"all peaks\")\n",
    "    ax5.hist(peaks[s1_peaks][\"area\"], bins=area_bins, histtype=\"step\", range=(0,area_right_boundary), label = \"s1\")\n",
    "    ax5.set_xlabel(\"peak area [p.e.]\")\n",
    "    #ax5.set_ylabel(\"#\")\n",
    "    ax5.set_xlim((0,area_right_boundary))\n",
    "    ax5.legend(loc=\"best\")\n",
    "    ax5.set_yscale(\"log\")\n",
    "    \n",
    "    ax6.set_title(\"number of peaks in events\")\n",
    "    ax6.hist(events[\"n_peaks\"], bins=10, histtype=\"step\", range=(0,10), align=\"left\")\n",
    "    ax6.set_xlabel(\"n_peaks\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Now finding events that contain >=2 peaks\n",
    "### Then plotting energy of first peak (ordered by area) vs the second peak\n",
    "\n",
    "multi_peak_events = events[events[\"n_peaks\"]>= 2]\n",
    "\n",
    "peak_by_event = group_by(peaks, \"Event\")\n",
    "\n",
    "main_peaks = []\n",
    "secondary_peaks = []\n",
    "\n",
    "for event_peaks in peak_by_event:\n",
    "    #print(event_peaks[\"area\"])\n",
    "    event_peaks = sorted(event_peaks, key= lambda x : x[\"area\"],reverse=True)\n",
    "    #print(event_peaks[0][\"area\"])\n",
    "    if len(event_peaks)<= 1:\n",
    "        continue\n",
    "    if event_peaks[0][\"type\"] != b\"s1\":\n",
    "        continue\n",
    "    if event_peaks[1][\"type\"] != b\"s1\":\n",
    "        continue\n",
    "    main_peaks.append(event_peaks[0])\n",
    "    secondary_peaks.append(event_peaks[1])\n",
    "    \n",
    "\n",
    "main_areas = [peak[\"area\"] for peak in main_peaks]\n",
    "secondary_areas =[peak[\"area\"] for peak in secondary_peaks]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.plot(main_areas, secondary_areas, \"k,\")\n",
    "ax.set_xlabel(\"area of main s1 peak [p.e.]\")\n",
    "ax.set_ylabel(\"area of secondary s1 peak [p.e.]\")\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
