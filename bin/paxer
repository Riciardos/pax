#!/usr/bin/env python
""" Processor for Analyzing XENON - command line interface """

import argparse
import os
import multiprocessing
from itertools import zip_longest

from pax import core

def grouper(iterable, n, fillvalue=None):
    "Collect data into fixed-length chunks or blocks"
    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx"
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)

class Consumer(multiprocessing.Process):

    def __init__(self, task_queue, result_queue,
                 config_names, config_path, config_dict):
        multiprocessing.Process.__init__(self)
        self.task_queue = task_queue
        self.result_queue = result_queue

# Log level control
parser.add_argument('--log', default=None, help="Set log level, e.g. 'debug'")

# Configuration control
# Pass in a name to use a pre-cooked config from config:
parser.add_argument(
    '--config',
    default='XENON100',
    choices=core.get_named_configuration_options(),
    nargs='+',
    help="Name(s) of the pax configuration(s) to use."
)
# ... or pass in a path to your own config file:
parser.add_argument(
    '--config_path',
    default=[],
    nargs='+',
    help="Path(s) of the configuration file(s) to use."
)
# ... or load the configuration from a previous processed data file
parser.add_argument(
    '--redo',
    default='',
    help="Path of the HDF5 data file to redo."
)

# Plotting override
plotting_control_group = parser.add_mutually_exclusive_group()
plotting_control_group.add_argument(
    '--plot',
    action='store_const',
    const=True,
    help='Plot summed waveforms on screen',
)
plotting_control_group.add_argument(
    '--plot_to_dir',
    help='Save summed waveform plots in directory',
)

# Control events to process
parser.add_argument('--event',
                    type=int,
                    nargs='+',
                    help="Process particular event(s).")
parser.add_argument('--stop_after',
                    type=int,
                    help="Stop after STOP_AFTER events have been processed.")

args = parser.parse_args()

# Take config from previous file
if args.redo:
    from pandas import HDFStore
    import json
    file_to_redo = core.data_file_name(args.redo)
    store = HDFStore(file_to_redo)
    if len(store['pax_info']) > 1:
        print("Warning: This file contains data from several processings. Will use config from last!\n")
    override_dict = json.loads(store['pax_info'].iloc[-1]['configuration_json'])
    # Add _redone to output name, unless user has specified an output name
    if not args.output:
        redo_path, ext = os.path.splitext(args.redo)    # Remove .hdf from path
        redo_path += '_redone'
        print("Output path of redone processing not specified: will write to %s\n" % redo_path)
        args.output = redo_path
    store.close()
else:
    override_dict = {'pax': {}}

for argname, configname in (
        ('input',      'input_name'),
        ('output',     'output_name'),
        ('log',        'logging_level'),
        ('stop_after', 'stop_after'),
        ('event',      'events_to_process'),
    ):
    value = getattr(args, argname)
    if value is not None:
        override_dict['pax'][configname] = value

# Overrides for plotting
if args.plot_to_dir or args.plot :
    override_dict['pax']['output'] = 'Plotting.PlotEventSummary'
    if args.plot_to_dir:
        override_dict['Plotting.PlotEventSummary'] = {'output_dir': args.plot_to_dir}

##
# Load configuration and run the processor
##
override_dict['pax']['plugin_group_names'] = ['input']
p = core.Processor(config_names=args.config,
                   config_paths=args.config_path,
                   config_dict=override_dict)

override_dict['pax']['plugin_group_names'] = ['dsp', 'transform']

# Establish communication queues
tasks = multiprocessing.JoinableQueue()
results = multiprocessing.Queue()

# Start consumers
num_consumers = multiprocessing.cpu_count()
p.log.info('Creating %d consumers',
           num_consumers)
consumers = [ Consumer(tasks, results,
                       args.config,
                       args.config_path,
                       override_dict) for i in range(num_consumers) ]
for w in consumers:
    w.start()

# Enqueue jobs
num_jobs = 0

for events in grouper(p.get_events(), 10):
    tasks.put(events)
    num_jobs += 1

p.shutdown()

# Add a poison pill for each consumer
for i in range(num_consumers):
    tasks.put(None)

# Wait for all of the tasks to finish
tasks.join()

override_dict['pax']['plugin_group_names'] = ['output']
p = core.Processor(config_names=args.config,
                   config_paths=args.config_path,
                   config_dict=override_dict)

# Start printing results
while num_jobs:

    for event in results.get():
        p.process_event(event)
    num_jobs -= 1

p.shutdown()