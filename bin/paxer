#!/usr/bin/env python
""" Processor for Analyzing XENON - command line interface

This is the main entry point for running standalone pax.  You can configure via
the command line most operations for running with pax.  Typically, you'll
specify a configuration via the --config command line argument.
"""

import argparse
import os
import sys
import copy
try:
    import queue
except ImportError:
    import Queue as queue   #noqa
import multiprocessing

import pax    # For version
from pax import core, utils, formats

from collections import OrderedDict

# Make the output plugin aliases
# Don't know yet if we want to display these ordered lexically or conceptually in --help:
# work with an ordereddict to store the conceptual order in case we change our minds
output_plugin_aliases = OrderedDict([
    ('none',  'Dummy.DummyOutput'),
    ('plot',  'Plotting.PlotEventSummary'),
    ('plot_interactive',  'Plotting.PeakViewer'),
])
# Add output aliases from TableWriter formats
output_plugin_aliases.update([(fc, ('Table.TableWriter', {'output_format': fc}))
                              for fc in formats.flat_data_formats.keys()])
output_plugin_aliases.update([
    # Zipped formats -- allow arbitrary event numbering
    ('zpickle', 'Pickle.WriteZippedPickles'),
    ('zbson', 'BSON.WriteZippedBSON'),

    # Non-zipped formats
    ('bson',  'BSON.WriteBSON'),
    ('json',  'BSON.WriteJSON'),
    ('xed',   'XED.WriteXED'),

    # Old raw formats (deprecated / problematic)
    ('_raw_pickles', 'Pickle.WriteToPickleFile'),
    ('_avro',        'Avro.WriteAvro'),

    # Formats that don't have a plugin to read data back
    ('raw_dump',     'RawWaveformDump.DumpSumWaveformToBinary'),
    ('mongo',        'Mongo.MongoDBWriteTriggered')
])

input_plugin_aliases = OrderedDict([
    ('none',  'Dummy.DummyInput'),
    ('xed',      'XED.ReadXED'),

    # Zipped formats
    ('zbson',   'BSON.ReadZippedBSON'),
    ('zpickle', 'Pickle.ReadZippedPickles'),

    # Nonzipped formats
    ('bson',    'BSON.ReadBSON'),
    ('json',    'BSON.ReadJSON'),
    ('avro',    'Avro.ReadAvro'),
])
input_plugin_aliases.update([(fc, ('Table.TableReader', {'format': fc}))
                             for fc in formats.flat_data_formats.keys()])
input_plugin_aliases.update([
    # Simulator input formats shouldn't be here: if you load simulated events you want a different config as well,
    # so you still want to use the Simulator ini file.

    # Mongo
    ('mongo_untriggered', 'MongoDBReadUntriggered'),
    ('mongo_untriggered', 'MongoDBReadUntriggered'),

    # Deprecated formats. Note some plugins have deprecated write code but not read code.
    ('_raw_pickles',  'Pickle.DirWithPickleFiles'),
])


class BaseProcess(multiprocessing.Process):

    """Base class for starting pax threads
    """

    def __init__(self, task_queue, result_queue,
                 input_done, process_done, output_done,
                 config_names, config_path, config_dict):
        multiprocessing.Process.__init__(self)

        # Queues for feeding events in and out
        self.task_queue = task_queue
        self.result_queue = result_queue

        # Multiprocessing 'Events'. These are booleans that indicated whether
        # each stage has finished.
        self.input_done = input_done
        self.process_done = process_done
        self.output_done = output_done

        # pax configuations
        self.config_names = config_names
        self.config_path = config_path
        self.config_dict = config_dict

    def run(self):
        # Defined in subclass
        raise NotImplementedError()


class ProcessorEvents(BaseProcess):

    """Thread for processing single events

    This thread will be fed via the task queue and report its results via the
    result queue.  It will initialize its own 'pax' Processor instance.  It
    waits until it has received a 'poisson pill', which tells it to shut down.
    """

    def run(self):
        # Initialize pax instance
        p = core.Processor(config_names=self.config_names,
                           config_paths=self.config_path,
                           config_dict=self.config_dict)

        # Loop until a 'poisson pill' found (next_events == None)
        while True:
            next_events = self.task_queue.get()
            answer = []
            if next_events is None:  # Poison pill of None means shutdown
                p.log.info('Exiting')
                p.shutdown()
                self.task_queue.task_done()
                break

            # If not None, means these are events to process
            for event in next_events:
                answer.append(p.process_event(event))

            # Notify queue that these events processed
            self.task_queue.task_done()

            # Put output to result queue to await being picked up by Output
            # thread
            self.result_queue.put(answer)

        return


class OutputEvents(BaseProcess):

    """Thread for writing events to disk

    Typically, there should only be one Output instance since often output
    operations are not parallelizable.
    """

    def run(self):
        # Initialize pax instance
        p = core.Processor(config_names=self.config_names,
                           config_paths=self.config_path,
                           config_dict=self.config_dict)

        #  Wait until can_end == True
        while True:
            # Need to check if we can end before we fetch events because
            # of the race condition where input and processing are done, but
            # there are still events left in the results queue waiting to be
            # processed
            can_end = self.input_done.is_set() and self.process_done.is_set()

            # Useful statistics
            print('input_done:', self.input_done.is_set(),
                  'process_done:', self.process_done.is_set(),
                  'output_done:', self.output_done.is_set(),
                  'blocks waiting input:', self.task_queue.qsize(),
                  'blocks waiting output:', self.result_queue.qsize())

            try:
                # Get events, or raise queue.Empty if timed out
                next_events = self.result_queue.get(block=True,
                                                    timeout=1)  # second

                # If events, write them to output
                for event in next_events:
                    p.process_event(event)

                # Tell result queue that events processed
                self.result_queue.task_done()
            except queue.Empty:
                # If queue is empty, and input and processing done, then exit
                # the while loop.
                if can_end:
                    self.output_done.set()
                    p.shutdown()
                    break

        return


def main():
    args = get_args()
    if args.version:
        print(pax.__version__)
        exit()

    # Compute numbers of CPUs that can be used
    max_cpus = multiprocessing.cpu_count()
    if args.cpus == 'all':
        args.cpus = max_cpus
    else:
        args.cpus = int(args.cpus)

    override_dict = {'pax': {}}

    # Feed certain command line args into pax configuration format
    for argname, configname in (('input',       'input_name'),
                                ('output',      'output_name'),
                                ('log',         'logging_level'),
                                ('stop_after',  'stop_after'),
                                ('event',       'events_to_process'),
                                ('event_numbers_file', 'event_numbers_file'),):
        value = getattr(args, argname)
        if value is not None:
            override_dict['pax'][configname] = value

    # Process input type options
    override_dict['pax']['input'] = []
    for pa in wraplist(args.input_type):
        bla = input_plugin_aliases[pa]
        if isinstance(bla, tuple):
            # We have a plugin name, extra options tuple
            plugin_name, override_dict[plugin_name] = bla
        else:
            plugin_name = bla
        override_dict['pax']['input'].append(plugin_name)

    # Process output type options. Code is almost the same... sorry!
    override_dict['pax']['output'] = []
    for pa in wraplist(args.output_type):
        bla = output_plugin_aliases[pa]
        if isinstance(bla, tuple):
            # We have a plugin name, extra options tuple
            plugin_name, override_dict[plugin_name] = bla
        else:
            plugin_name = bla
        override_dict['pax']['output'].append(plugin_name)

    # Overrides for plotting
    if args.plot_to_dir or args.plot:
        override_dict['pax']['output_name'] = 'SCREEN'
        override_dict['pax']['output'] = 'Plotting.PlotEventSummary'
    if args.plot_to_dir:
        override_dict['pax']['output_name'] = args.plot_to_dir
    if args.plot_interactive:
        override_dict['pax']['output_name'] = 'SCREEN'
        override_dict['pax']['output'] = 'Plotting.PeakViewer'

    ##
    # Single-core processing
    ##
    if args.cpus == 1:
        pax_instance = core.Processor(config_names=args.config,
                                      config_paths=args.config_path,
                                      config_dict=override_dict)

        try:
            pax_instance.run()
        except (KeyboardInterrupt, SystemExit):
            print("\nShutting down all plugins...")
            pax_instance.shutdown()
            print("Exiting")
            sys.exit()
    else:  # Parallel processing
        if os.name == 'nt':
            raise NotImplementedError("Pax parallelization is not supported "
                                      "under Windows (due to lack of fork).")

        override_dict['pax']['plugin_group_names'] = ['input']
        p = core.Processor(config_names=args.config,
                           config_paths=args.config_path,
                           config_dict=copy.deepcopy(override_dict))

        override_dict['pax']['plugin_group_names'] = ['dsp', 'transform']

        # Keep track of processing state that threads can see
        input_done = multiprocessing.Event()
        process_done = multiprocessing.Event()
        output_done = multiprocessing.Event()

        # Establish communication queues
        tasks = multiprocessing.JoinableQueue()
        results = multiprocessing.JoinableQueue()

        # Start consumers
        num_consumers = args.cpus
        p.log.info('Creating %d consumers',
                   num_consumers)
        consumers = [ProcessorEvents(tasks, results,
                                     input_done, process_done, output_done,
                                     args.config,
                                     args.config_path,
                                     config_dict=copy.deepcopy(override_dict)) for _ in range(num_consumers)]

        override_dict['pax']['plugin_group_names'] = ['output']
        consumer_output = OutputEvents(tasks, results,
                                       input_done, process_done, output_done,
                                       args.config,
                                       args.config_path,
                                       config_dict=copy.deepcopy(override_dict))

        # Start all worker threads
        for w in consumers + [consumer_output]:
            w.start()

        # Enqueue jobs
        events = []
        n = 10  # chunk in threads (TODO: what is best n?)

        for event in p.get_events():
            events.append(event)
            if len(events) > n:
                tasks.put(events)
                events = []

        # If anything left over
        if len(events):
            tasks.put(events)
        p.shutdown()

        # Input stage done
        input_done.set()

        # Put poison pills to tell thread to quit
        for i in range(num_consumers):
            tasks.put(None)

        print("Wait for consumers to finish")
        tasks.join()  # blocks until processing done

        process_done.set()  # processing done

        output_done.wait()  # wait until output done
        print("All events processed.  Exiting...")


def get_args():
    """Process command line arguments"""
    parser = argparse.ArgumentParser(description="Processor for XENON data",
                                     epilog="""For more information, please see the pax documentation at
                                               http://xenon1t.github.io/pax/ or the pax development site at
                                               https://github.com/XENON1T/pax.""")

    # Input and output control
    parser.add_argument('--input', default=None,
                        help="File, database or directory to read events from.",)
    parser.add_argument('--output', default=None,
                        help="File, database or directory to write events to. "
                             "Defaults to name constructed from current date and time (YYMMDD_hhmmss). "
                             "For plotting to screen, use SCREEN.")

    output_type_options = list(reversed(sorted(output_plugin_aliases.keys())))
    parser.add_argument('--output_type', default='hdf5',
                        nargs='+', choices=output_type_options,
                        help='Output format/plugin(s) to use: default is hdf5. '
                             'Should be a space-separated list; allowed values are: ' +
                             ', '.join(output_type_options) + '.\n' +
                             'Use with --config reduce_raw_data if you want to write raw data!',
                        metavar='OUTPUT_TYPE',
                        )
    input_type_options = list(reversed(sorted(input_plugin_aliases.keys())))
    parser.add_argument('--input_type', default='xed',
                        choices=input_type_options,
                        help='Input format/plugin to use: default is xed. '
                             'Allowed values are: ' +
                             ', '.join(input_type_options) + '.\n' +
                             'Use with --config Reprocess if you want to read processed data!',
                        metavar='INPUT_TYPE',)

    # Parallelization control
    parser.add_argument('--cpus', default=1,
                        help="Number of CPUs to use. Default is 1; can be 'all'.",
                        nargs='?')

    # Log level control
    parser.add_argument('--log', default=None,
                        help="Set log level, e.g. 'debug'")

    # Configuration control
    # Pass in a name to use a pre-cooked config from config:
    config_options = utils.get_named_configuration_options()
    parser.add_argument('--config',
                        default='XENON100',
                        choices=config_options,
                        nargs='+',
                        metavar='CONFIG',
                        help="Name(s) of the pax configuration(s) to use: default is XENON100. "
                             "Should be a space-separated list; allowed-values are: " + \
                             ', '.join(config_options))
    # ... or a path to your own config file:
    parser.add_argument('--config_path',
                        default=[],
                        nargs='+',
                        help="Path(s) of the configuration file(s) to use.")

    # Control events to process
    parser.add_argument('--event',
                        type=int,
                        nargs='+',
                        help="Process particular event number(s).")
    parser.add_argument('--event_numbers_file',
                        type=str,
                        help="Name of file containing newline-separated event number(s) to process.")
    parser.add_argument('--stop_after',
                        type=int,
                        help="Stop after STOP_AFTER events have been processed.")

    # Plotting override
    plotting_control_group = parser.add_mutually_exclusive_group()
    plotting_control_group.add_argument('--plot',
                                        action='store_const',
                                        const=True,
                                        help='Plot summed waveforms on screen. '
                                             'Equivalent to --output_type plot --output SCREEN.')
    plotting_control_group.add_argument('--plot_interactive',
                                        action='store_const',
                                        const=True,
                                        help='Plot interactive peak browser on screen. '
                                             'Equivalent to --output_type plot_interactive --output SCREEN.')
    plotting_control_group.add_argument('--plot_to_dir',
                                        help='Save summed waveform plots in directory. '
                                             'Equivalent to --output_type plot --output your_directory.')

    # Version number printing
    parser.add_argument('--version',  action='store_true',
                        help="Print current pax version, then exit")

    return parser.parse_args()


def wraplist(x):
    """Returns [x] if x is a string or not iterable, returns x otherwise"""
    if isinstance(x, str):
        return [x]
    try:
        x[0]
    except TypeError:
        return [x]
    return x


if __name__ == "__main__":
    main()
