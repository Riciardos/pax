#!/usr/bin/env python
""" Processor for Analyzing XENON - command line interface """

import argparse
import os
import multiprocessing

from pax import core


class Consumer(multiprocessing.Process):

    def __init__(self, task_queue, result_queue,
                 config_names, config_path, config_dict):
        multiprocessing.Process.__init__(self)
        self.task_queue = task_queue
        self.result_queue = result_queue

        self.config_names = config_names
        self.config_path = config_path
        self.config_dict = config_dict

    def run(self):
        proc_name = self.name

        p = core.Processor(config_names=self.config_names,
                           config_paths=self.config_path,
                           config_dict=self.config_dict)

        while True:
            next_event = self.task_queue.get()
            if next_event is None:
                # Poison pill means shutdown
                print(('%s: Exiting' % proc_name))
                self.task_queue.task_done()
                break

            answer = p.process_event(next_event)

            self.task_queue.task_done()
            self.result_queue.put(answer)
        return

##
# Parse command line arguments
##
parser = argparse.ArgumentParser(description="Process XENON1T data")

# Input and output overrides
parser.add_argument('--input',  default=None, help="File, database or directory to read events from", nargs='?')
parser.add_argument('--output', default=None, help="File, database or directory to write events to",  nargs='?')

# Log level control
parser.add_argument('--log', default=None, help="Set log level, e.g. 'debug'")

# Configuration control
# Pass in a name to use a pre-cooked config from config:
parser.add_argument(
    '--config',
    default='XENON100',
    choices=core.get_named_configuration_options(),
    nargs='+',
    help="Name(s) of the pax configuration(s) to use."
)
# ... or pass in a path to your own config file:
parser.add_argument(
    '--config_path',
    default=[],
    nargs='+',
    help="Path(s) of the configuration file(s) to use."
)
# ... or load the configuration from a previous processed data file
parser.add_argument(
    '--redo',
    default='',
    help="Path of the HDF5 data file to redo."
)

# Plotting override
plotting_control_group = parser.add_mutually_exclusive_group()
plotting_control_group.add_argument(
    '--plot',
    action='store_const',
    const=True,
    help='Plot summed waveforms on screen',
)
plotting_control_group.add_argument(
    '--plot_to_dir',
    help='Save summed waveform plots in directory',
)

# Control events to process
parser.add_argument('--event',
                    type=int,
                    nargs='+',
                    help="Process particular event(s).")
parser.add_argument('--stop_after',
                    type=int,
                    help="Stop after STOP_AFTER events have been processed.")

args = parser.parse_args()

# Take config from previous file
if args.redo:
    from pandas import HDFStore
    import json
    file_to_redo = core.data_file_name(args.redo)
    store = HDFStore(file_to_redo)
    if len(store['pax_info']) > 1:
        print("Warning: This file contains data from several processings. Will use config from last!\n")
    override_dict = json.loads(store['pax_info'].iloc[-1]['configuration_json'])
    # Add _redone to output name, unless user has specified an output name
    if not args.output:
        redo_path, ext = os.path.splitext(args.redo)    # Remove .hdf from path
        redo_path += '_redone'
        print("Output path of redone processing not specified: will write to %s\n" % redo_path)
        args.output = redo_path
    store.close()
else:
    override_dict = {'pax': {}}

for argname, configname in (
        ('input',      'input_name'),
        ('output',     'output_name'),
        ('log',        'logging_level'),
        ('stop_after', 'stop_after'),
        ('event',      'events_to_process'),
    ):
    value = getattr(args, argname)
    if value is not None:
        override_dict['pax'][configname] = value

# Overrides for plotting
if args.plot_to_dir or args.plot :
    override_dict['pax']['output'] = 'Plotting.PlotEventSummary'
    if args.plot_to_dir:
        override_dict['Plotting.PlotEventSummary'] = {'output_dir': args.plot_to_dir}

##
# Load configuration and run the processor
##
override_dict['pax']['plugin_group_names'] = ['input']
p = core.Processor(config_names=args.config,
               config_paths=args.config_path,
               config_dict=override_dict)

override_dict['pax']['plugin_group_names'] = ['dsp', 'transform']

# Establish communication queues
tasks = multiprocessing.JoinableQueue()
results = multiprocessing.Queue()

# Start consumers
num_consumers = multiprocessing.cpu_count()
print('Creating %d consumers' % num_consumers)
consumers = [ Consumer(tasks, results,
                       args.config,
                       args.config_path,
                       override_dict)
              for i in range(num_consumers) ]
for w in consumers:
    w.start()

# Enqueue jobs
num_jobs = 0
for event in p.get_events():
    tasks.put(event)
    num_jobs += 1

p.shutdown()

# Add a poison pill for each consumer
for i in range(num_consumers):
    tasks.put(None)

# Wait for all of the tasks to finish
tasks.join()

override_dict['pax']['plugin_group_names'] = ['output']
p = core.Processor(config_names=args.config,
                   config_paths=args.config_path,
                   config_dict=override_dict)

# Start printing results
while num_jobs:
    p.process_event(results.get())
    num_jobs -= 1

p.shutdown()