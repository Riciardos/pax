#!/usr/env/python
from datetime import datetime
import time
import argparse
import multiprocessing

from pax import core, parallel, utils

def main():

    parser = argparse.ArgumentParser(description="Listen to a RabbitMQ server for instructions to create pax instances",)

    parser.add_argument('--cpus', default=2,
                        help='Maximum number of CPUS to dedicate to pax = maximum number of pax instances to start.')

    parallel.add_rabbit_command_line_args(parser)

    parser.add_argument('--startup_queue', default='pax_startup',
                        help='Name for the pax startup request queue, usually just leave as pax_startup (default).')

    parser.add_argument('--crash_watch_fanout', default='pax_crashes',
                        help='Name for the pax crash reporting fanout (rabbitmq exchange), '
                             'usually just leave as pax_crashes (default).')


    args = parser.parse_args()

    # Setup the startup queue. Here we will listen for messages for starting pax, which should look like
    #  (pax_id, {config_names=..., config_paths=..., etc}))
    url = parallel.url_from_parsed_args(args)
    startup_queue = parallel.RabbitQueue(args.startup_queue, url)
    manager = multiprocessing.Manager()

    # Setup the crash-watching fanout. Here we can send/receive messages denoting a pax crash
    #  (pax_id, extra_info)
    # where extra info should (at least when I get around to it ;-) be a nice message about the cause of the crash.
    # When a crash message is enountered all paxes with pax_id will be terminated (SIGTERM).
    # paxmaker can also send such a message if it encounters a crash in pax,
    # which will fan out to every other connected paxmaker.
    crash_fanout = parallel.RabbitFanOut(args.crash_watch_fanout, url)

    running_paxes = []
    max_paxes = args.cpus

    while True:
        running_paxes = parallel.check_local_processes_while_remote_processing(running_paxes, crash_fanout)

        utils.refresh_status_line("[Paxmaker] Listening to %s. %s: %s paxes running, %d pax slots available." % (
            url,
            datetime.now(),
            len(running_paxes),
            max_paxes - len(running_paxes),
        ))

        # Check for and handle pax startup requests
        while True:
            try:
                msg = startup_queue.get()
            except parallel.Empty:
                break

            pax_id, kwargs = msg

            if len(running_paxes) >= max_paxes:
                # We're already full; can't start another pax. Let someone else do it.
                print("Start pax %s message received, but out of capacity. Putting back on queue." % pax_id)
                startup_queue.put(msg)
                break

            # Start a new pax and append it to the list of running paxes
            print("Starting pax %s" % pax_id)
            kwargs.setdefault('config_dict', {})
            kwargs['config_dict'].setdefault('pax', {})
            kwargs['config_dict']['pax']['autorun'] = True
            newpax = parallel.start_safe_processor(manager, **kwargs)
            newpax.pax_id = pax_id
            running_paxes.append(newpax)

        time.sleep(1)


if __name__ == '__main__':
    main()

